# -*- coding: utf-8 -*-
"""Loan_approval_model_c.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iz89fjIFEdVHNe662RHlPu_aThBe9WEm
"""

! git clone https://github.com/wlifferth/ghw-2023-02

import pandas as pd

df = pd.read_csv('ghw-2023-02/loan_applications.csv')
df.head()

from sklearn.model_selection import train_test_split
df['is_creditworthy'] = df['will_default'] == False

X_train, X_test, y_train, y_test = train_test_split(df[['credit_score', 'race', 'zipcode']], df['is_creditworthy'], test_size = 0.3, random_state=42)

def evaluate_by_race(input_data, predictions, correct_answer):
  print(f'\tAccuracy: {sum(predictions == correct_answer) / len(predictions)}')  
  true_positive_rate = sum((predictions == correct_answer) & (correct_answer == True)) / sum(correct_answer == True)
  true_negative_rate = sum((predictions == correct_answer) & (correct_answer == False)) / sum(correct_answer == False)
  print(f'\tTPR: {true_positive_rate}')
  print(f'\tTNR: {true_negative_rate}')
  f1_values = []
  for race in sorted(input_data['race'].unique()):
    print(race)
    indices = input_data['race'] == race
    preds_by_race = predictions[indices]
    correct_answer_by_race = correct_answer[indices]
    print(f'\tAccuracy: {sum(preds_by_race == correct_answer_by_race) / len(preds_by_race)}')  
    true_positive_rate = sum((preds_by_race == correct_answer_by_race) & (correct_answer_by_race == True)) / sum(correct_answer_by_race == True)
    true_negative_rate = sum((preds_by_race == correct_answer_by_race) & (correct_answer_by_race == False)) / sum(correct_answer_by_race == False)
    f1_approximate = true_positive_rate * true_negative_rate
    f1_values.append(f1_approximate)
    print(f'\tTPR: {true_positive_rate}')
    print(f'\tTNR: {true_negative_rate}')
    print(f'\tf1_approximate: {f1_approximate}')

  min_f1 = min(f1_values)
  max_f1 = max(f1_values)
  print(f'min f1: {min_f1}')
  print(f'max f1: {max_f1}')
  print(f'f1 spread: {max_f1 - min_f1}')

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.linear_model import LogisticRegression

ct = ColumnTransformer([('one-hot-encoder', OneHotEncoder(), ['race', 'zipcode'])], remainder='passthrough')
X_train_vec = ct.fit_transform(X_train)
X_test_vec = ct.fit_transform(X_test)
model = LogisticRegression(class_weight = {1:1, 0:5})
model.fit(X_train_vec, y_train)
model.score(X_test_vec, y_test)

base_model_predictions = model.predict(X_test_vec)
evaluate_by_race(X_test, base_model_predictions, y_test)

!pip install scikit-lego

from sklego.linear_model import EqualOpportunityClassifier

X_train.head()

X_train_vec.toarray()[0]

X_train_vec.toarray()[3]

X_train['is_creditworthy'] = y_train
X_train['weight'] = X_train['is_creditworthy'].apply(lambda x: {True: 1, False: 5}[x])
X_train.head(n=10)

X_train_weighted = X_train.sample(frac=5, replace=True, weights=X_train['weight'])
X_train_weighted.head()

y_train_weighted = X_train_weighted['is_creditworthy']
X_train_weighted = X_train_weighted.drop(['is_creditworthy', 'weight'], axis=1)

X_train_weighted

ct = ColumnTransformer([('one-hot-encoder', OneHotEncoder(), ['race', 'zipcode'])], remainder='passthrough')
X_train_weighted_vec = ct.fit_transform(X_train_weighted)
X_test_vec = ct.transform(X_test)

eo_model = EqualOpportunityClassifier(positive_target = True, covariance_threshold=0.05, sensitive_cols=[0, 1, 2, 3])

eo_model.fit(X_train_weighted_vec.toarray(), y_train_weighted)

eo_model.score(X_test_vec.toarray(), y_test)

eo_model_predictions = eo_model.predict(X_test_vec.toarray())
evaluate_by_race(X_test, eo_model_predictions, y_test)

"""#Demographic Parity """

from sklego.linear_model import DemographicParityClassifier

dp_weighted_model = DemographicParityClassifier(covariance_threshold=0.05, sensitive_cols=[0, 1, 2, 3])
dp_weighted_model.fit(X_train_weighted_vec.toarray(), y_train_weighted)
dp_weighted_model.score(X_test_vec.toarray(), y_test)

dp_weighted_predictions = dp_weighted_model.predict(X_test_vec.toarray())
evaluate_by_race(X_test, dp_weighted_predictions, y_test)